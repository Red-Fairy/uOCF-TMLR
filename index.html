<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Unsupervised Discovery of Object-Centric Neural Fields</title>
  <!-- Bootstrap -->
  <link rel="preconnect" href="https://rsms.me/">
  <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
  <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
  <link href="css/main.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <style>
    body {
      background: #ffffff;
      color: #333;
      font-family: "Google Sans", sans-serif;
    }

    .jumbotron {
      padding: 40px 0;
      background-color: #ffffff;
    }

    h2 {
      font-size: 44px;
      font-weight: bold;
      font-family: "Google Sans", sans-serif;
      margin-bottom: 10px;
    }

    h3 {
      font-size: 28px;
      color: #7a7a7a;
      margin-top: 1px;
      margin-bottom: 10px;
    }

    hr {
      border-top-color: #bbbbbb;
    }

    .text-center {
      text-align: center;
    }

    .container {
      padding: 0 10px;
    }

    .row {
      margin: 0 -20px;
    }

    .icon-container {
      display: flex;
      /* Use flexbox to layout icons */
      flex-wrap: wrap;
      /* Allows icons to wrap onto the next line if needed */
      justify-content: center;
      gap: 2px;
      margin-top: 5px;
    }

    .icon {
      display: flex;
      align-items: center;
      padding: 10px;
      background-color: #333;
      color: white;
      border-radius: 20px;
      font-family: "Google Sans", sans-serif;
      font-size: 14px;
      width: 100px;
      text-decoration: none;
      justify-content: center;
    }

    /* hover icon */
    .icon:hover {
      background-color: #FFFFFF;
    }

    .icon i {
      margin-right: 8px;
    }
  </style>
</head>

<!-- cover -->
<section>
  <div class="jumbotron text-center mt-0">
    <div class="container-fluid">
      <div class="row">
        <div class="col">
          <h2>Unsupervised Discovery of<br>Object-Centric Neural Fields</h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <img src="assets/images/teaser.png" alt="input" class="img-responsive graph" width="100%" />
          <br>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<!-- abstract -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12">
        <h3><strong>Abstract</strong></h3>
        <hr style="margin-top:0px">
        <p class="text-justify">
          We study inferring 3D object-centric scene representations from a single image. While
          recent methods have shown potential in unsupervised 3D object discovery, they are limited
          in generalizing to unseen spatial configurations. This limitation stems from the lack of
          translation invariance in their 3D object representations. Previous 3D object discovery
          methods entangle objects' intrinsic attributes like shape and appearance with their 3D
          locations. This entanglement hinders learning generalizable 3D object representations. To
          tackle this bottleneck, we propose the unsupervised discovery of Object-Centric neural
          Fields (uOCF), which integrates translation invariance into the object representation. To
          allow learning object-centric representations from limited real-world images, we further
          introduce an object prior learning method that transfers object-centric prior knowledge
          from a synthetic dataset. To evaluate our approach, we collect four new datasets, including
          two real kitchen environments. Extensive experiments show that our approach significantly
          improves generalization and sample efficiency, and enables unsupervised 3D object discovery
          in real scenes. Notably, uOCF demonstrates zero-shot generalization to unseen objects from
          a single real image.
        </p>
      </div>
    </div>
  </div>
</section>
<br>

<section>
  <div class="container">
    <h3><strong>Inferring object representations from a single image</strong></h3>
    <hr style="margin-top:0px">
    <p class="text-justify">
      Given a real image (the first frame) with visually-rich objects, uOCF infers the factorized 3D object-centric
      scene
      representations, enabling reconstruction and manipulation from arbitrary novel views.
    </p>
    <div class="row">
      <!-- First Video -->
      <div class="col-md-6 text-center">
        <video width="100%" height="auto" controls>
          <source src="assets/videos/video-kiteasy.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <!-- Second Video -->
      <div class="col-md-6 text-center">
        <video width="100%" height="auto" controls>
          <source src="assets/videos/video-kithard.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
  </div>
</section>
<br>

<!-- Video -->
<section>
  <div class="container">
    <h3><strong>Video</strong></h3>
    <hr style="margin-top:0px">
    <div class="row">
      <div class="col-12 text-center">
        <video width="100%" height="auto" controls>
          <source src="assets/videos/video.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
  </div>
</section>
<br>

<section>
  <div class="container">
    <h3><strong>Novel View Synthesis</strong></h3>
    <div class="row">
      <div class="col-12 text-center">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <img src="assets/images/novel-view-synthesis.png" alt="input" class="img-responsive graph" width="100%" />
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<section>
  <div class="container">
    <h3><strong>Robustness to occlusion</strong></h3>
    <div class="row">
      <div class="col-12 text-center">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <img src="assets/images/occlusion.gif" alt="input" class="img-responsive graph" width="100%" />
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<section>
  <div class="container">
    <h3><strong>Scene segmentation</strong></h3>
    <div class="row">
      <div class="col-12 text-center">
        <hr style="margin-top:0px">
        <div class="row justify-content-center" style="align-items:center; display:flex" width="100%">
          <img src="assets/images/scene-segmentation.png" alt="input" class="img-responsive graph" width="100%" />
        </div>
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <img src="assets/images/segmentation.gif" alt="input" class="img-responsive graph" width="100%" />
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<section>
  <div class="container">
    <h3><strong>Method</strong></h3>
    <div class="row">
      <div class="col-12">
        <hr style="margin-top:0px">
        <p class="text-justify">
          Our model consists of an encoder, a latent inference module, and a decoder. The encoder extracts features
          from the input image. The latent inference module infers the objects' latent representations and positions
          in the underlying 3D scene from the obtained feature map. Finally, the object NeRF decoder decodes the
          latent representations and positions into the object-centric neural fields and composes them to reconstruct
          the scene.
        </p>
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <img src="assets/images/framework.png" alt="input" class="img-responsive graph" width="100%" />
        </div>
        <p class="text-justify">
          We introduce object-centric prior learning to address the inherent difficulty caused by the ambiguities in
          compositional scenes.
          The main idea is to learn object priors (e.g., physical
          coherence) from simple scenes (e.g., scenes with a single synthetic object), then leverage the obtained
          priors
          to learn from more real-world scenes that could potentially have very different scene geometry and spatial
          layout. An illustration is shown below.
        </p>
        <div class="row justify-content-center" style="align-items:center; display:flex;">
          <img src="assets/images/object-prior-learning.png" alt="input" class="img-responsive graph" width="100%" />
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      macros: {
        bm: ["{\\boldsymbol #1}", 1],
      }
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</body>

</html>